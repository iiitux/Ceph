# 监控OSD和PG

## 检查osd状态

```bash
[root@ceph01 ~]# ceph osd stat
3 osds: 3 up, 3 in
```

* `in`和`out`表示是否在集群内；
* `up`和`down`表示osd服务是否运行；

```bash
[root@ceph01 ~]# ceph osd tree
ID  CLASS WEIGHT  TYPE NAME           STATUS REWEIGHT PRI-AFF
 -1       0.02939 root default
 -9       0.00980     rack rack01
 -3       0.00980         host ceph01
  0   hdd 0.00980             osd.0       up  1.00000 1.00000
-10       0.00980     rack rack02
 -5       0.00980         host ceph02
  1   hdd 0.00980             osd.1       up  1.00000 1.00000
-11       0.00980     rack rack03
 -7       0.00980         host ceph03
  2   hdd 0.00980             osd.2       up  1.00000 1.00000
```

## 检查PG

```bash
[root@ceph01 ~]# ceph pg map 1.5f
osdmap e100 pg 1.5f (1.5f) -> up [0,2,1] acting [0,2,1]
```

* `e100`为osdmap版本号；
* `1.5f`为pg号，其中`1`为`pool num`，`5f`为`pg id`；
* `[0.2.1]`为up set内的osd；

```bash
[root@ceph01 ~]# ceph pg stat
128 pgs: 128 active+clean; 19 bytes data, 3396 MB used, 27293 MB / 30690 MB avail
```

* 检查pg状态；

```bash
[root@ceph01 ~]# ceph pg dump
dumped all
version 4215
stamp 2018-07-20 11:26:47.339032
last_osdmap_epoch 0
last_pg_scan 0
full_ratio 0
nearfull_ratio 0
......
......

1 2 0 0 0 0 19 31 31

sum 2 0 0 0 0 19 31 31
OSD_STAT USED  AVAIL  TOTAL  HB_PEERS PG_SUM PRIMARY_PG_SUM
2        1132M  9097M 10230M    [0,1]    128             39
1        1132M  9097M 10230M    [0,2]    128             46
0        1132M  9097M 10230M    [1,2]    128             43
sum      3396M 27293M 30690M
```

* dump pg信息；

```bash
[root@ceph01 ~]# ceph pg dump -o pg.json --format=json
dumped all
```

* pg信息dump成json格式；

```bash
[root@ceph01 ~]# ceph pg 1.5f query
```

* 查询某个pg信息；

## 定位对象

```bash
root@ceph01:~# rados put syslog /var/log/syslog -p rbd
root@ceph01:~# rados -p rbd ls
syslog
root@ceph01:~# ceph osd map rbd syslog
osdmap e97 pool 'rbd' (8) object 'syslog' -> pg 8.5e3867e2 (8.2) -> up ([2,0,4], p2) acting ([2,0,4], p2)
root@ceph01:~# rados rm -p rbd syslog
```

* syslog对象存放在pool 8,pg 8.2下。